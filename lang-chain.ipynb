{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-1.0.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain)\n",
      "  Using cached langchain_core-1.0.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting langgraph<1.1.0,>=1.0.0 (from langchain)\n",
      "  Using cached langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached langsmith-0.4.38-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\jaider.vargas-n\\downloads\\basic-langchain\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
      "Collecting pyyaml<7.0.0,>=5.3.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached pyyaml-6.0.3-cp311-cp311-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\jaider.vargas-n\\downloads\\basic-langchain\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.15.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached xxhash-3.6.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached ormsgpack-1.11.0-cp311-cp311-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting httpx>=0.25.2 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached orjson-3.11.4-cp311-cp311-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting requests>=2.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached zstandard-0.25.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting anyio (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting certifi (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.41.4-cp311-cp311-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl.metadata (38 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Using cached langchain-1.0.2-py3-none-any.whl (107 kB)\n",
      "Using cached langchain_core-1.0.1-py3-none-any.whl (467 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
      "Using cached langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
      "Using cached langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
      "Using cached langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Using cached langsmith-0.4.38-py3-none-any.whl (397 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Using cached pydantic_core-2.41.4-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "Using cached pyyaml-6.0.3-cp311-cp311-win_amd64.whl (158 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached orjson-3.11.4-cp311-cp311-win_amd64.whl (131 kB)\n",
      "Using cached ormsgpack-1.11.0-cp311-cp311-win_amd64.whl (112 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl (106 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached xxhash-3.6.0-cp311-cp311-win_amd64.whl (31 kB)\n",
      "Using cached zstandard-0.25.0-cp311-cp311-win_amd64.whl (506 kB)\n",
      "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, xxhash, urllib3, typing-inspection, tenacity, sniffio, pyyaml, pydantic-core, ormsgpack, orjson, jsonpointer, idna, h11, charset_normalizer, certifi, annotated-types, requests, pydantic, jsonpatch, httpcore, anyio, requests-toolbelt, httpx, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain\n",
      "\n",
      "   -- -------------------------------------  2/30 [urllib3]\n",
      "   -- -------------------------------------  2/30 [urllib3]\n",
      "   -- -------------------------------------  2/30 [urllib3]\n",
      "   ---- -----------------------------------  3/30 [typing-inspection]\n",
      "   ----- ----------------------------------  4/30 [tenacity]\n",
      "   -------- -------------------------------  6/30 [pyyaml]\n",
      "   -------- -------------------------------  6/30 [pyyaml]\n",
      "   ------------- -------------------------- 10/30 [jsonpointer]\n",
      "   ---------------- ----------------------- 12/30 [h11]\n",
      "   ---------------- ----------------------- 12/30 [h11]\n",
      "   ----------------- ---------------------- 13/30 [charset_normalizer]\n",
      "   ------------------ --------------------- 14/30 [certifi]\n",
      "   --------------------- ------------------ 16/30 [requests]\n",
      "   ---------------------- ----------------- 17/30 [pydantic]\n",
      "   ---------------------- ----------------- 17/30 [pydantic]\n",
      "   ---------------------- ----------------- 17/30 [pydantic]\n",
      "   ---------------------- ----------------- 17/30 [pydantic]\n",
      "   ---------------------- ----------------- 17/30 [pydantic]\n",
      "   ---------------------- ----------------- 17/30 [pydantic]\n",
      "   ---------------------- ----------------- 17/30 [pydantic]\n",
      "   ---------------------- ----------------- 17/30 [pydantic]\n",
      "   ---------------------- ----------------- 17/30 [pydantic]\n",
      "   ---------------------- ----------------- 17/30 [pydantic]\n",
      "   ------------------------- -------------- 19/30 [httpcore]\n",
      "   ------------------------- -------------- 19/30 [httpcore]\n",
      "   ------------------------- -------------- 19/30 [httpcore]\n",
      "   -------------------------- ------------- 20/30 [anyio]\n",
      "   -------------------------- ------------- 20/30 [anyio]\n",
      "   -------------------------- ------------- 20/30 [anyio]\n",
      "   ---------------------------- ----------- 21/30 [requests-toolbelt]\n",
      "   ---------------------------- ----------- 21/30 [requests-toolbelt]\n",
      "   ----------------------------- ---------- 22/30 [httpx]\n",
      "   ----------------------------- ---------- 22/30 [httpx]\n",
      "   ----------------------------- ---------- 22/30 [httpx]\n",
      "   ------------------------------ --------- 23/30 [langsmith]\n",
      "   ------------------------------ --------- 23/30 [langsmith]\n",
      "   ------------------------------ --------- 23/30 [langsmith]\n",
      "   ------------------------------ --------- 23/30 [langsmith]\n",
      "   ------------------------------ --------- 23/30 [langsmith]\n",
      "   -------------------------------- ------- 24/30 [langgraph-sdk]\n",
      "   --------------------------------- ------ 25/30 [langchain-core]\n",
      "   --------------------------------- ------ 25/30 [langchain-core]\n",
      "   --------------------------------- ------ 25/30 [langchain-core]\n",
      "   --------------------------------- ------ 25/30 [langchain-core]\n",
      "   --------------------------------- ------ 25/30 [langchain-core]\n",
      "   --------------------------------- ------ 25/30 [langchain-core]\n",
      "   --------------------------------- ------ 25/30 [langchain-core]\n",
      "   --------------------------------- ------ 25/30 [langchain-core]\n",
      "   --------------------------------- ------ 25/30 [langchain-core]\n",
      "   --------------------------------- ------ 25/30 [langchain-core]\n",
      "   --------------------------------- ------ 25/30 [langchain-core]\n",
      "   --------------------------------- ------ 25/30 [langchain-core]\n",
      "   --------------------------------- ------ 25/30 [langchain-core]\n",
      "   --------------------------------- ------ 25/30 [langchain-core]\n",
      "   ---------------------------------- ----- 26/30 [langgraph-checkpoint]\n",
      "   ------------------------------------- -- 28/30 [langgraph]\n",
      "   ------------------------------------- -- 28/30 [langgraph]\n",
      "   ------------------------------------- -- 28/30 [langgraph]\n",
      "   ------------------------------------- -- 28/30 [langgraph]\n",
      "   ------------------------------------- -- 28/30 [langgraph]\n",
      "   -------------------------------------- - 29/30 [langchain]\n",
      "   -------------------------------------- - 29/30 [langchain]\n",
      "   -------------------------------------- - 29/30 [langchain]\n",
      "   ---------------------------------------- 30/30 [langchain]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.11.0 certifi-2025.10.5 charset_normalizer-3.4.4 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jsonpatch-1.33 jsonpointer-3.0.0 langchain-1.0.2 langchain-core-1.0.1 langgraph-1.0.1 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.1 langgraph-sdk-0.2.9 langsmith-0.4.38 orjson-3.11.4 ormsgpack-1.11.0 pydantic-2.12.3 pydantic-core-2.41.4 pyyaml-6.0.3 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 typing-inspection-0.4.2 urllib3-2.5.0 xxhash-3.6.0 zstandard-0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU \"langchain[openai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 20, 'total_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CW2lc8TGQIJ4nrRgyAp4kfaX0qhXg', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--d95be0f2-621d-4198-b67d-a576790cdb98-0', usage_metadata={'input_tokens': 20, 'output_tokens': 3, 'total_tokens': 23, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(content=\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CW2ltuCmXjV0raIL3WZn5cLo55Xx9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--fe8d5eb7-a63f-45e7-a629-34d0bf5043d4-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello\")\n",
    "\n",
    "model.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])\n",
    "\n",
    "model.invoke([HumanMessage(\"Hello\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|C|iao|!||||"
     ]
    }
   ],
   "source": [
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi!\"})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao!\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
