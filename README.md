# üß† Proyecto: LangChain B√°sico con OpenAI

## üéØ Objetivo
Este proyecto implementa un **LLM Chain simple** utilizando el framework **LangChain** y el modelo **GPT-4o-mini** de OpenAI.  
El prop√≥sito es comprender la construcci√≥n b√°sica de un flujo *Prompt ‚Üí LLM ‚Üí Respuesta*, como base conceptual antes de desarrollar sistemas m√°s avanzados como los RAG (Retrieval-Augmented Generation).

---

## üß± Arquitectura del proyecto

El flujo de ejecuci√≥n en el notebook es el siguiente:

1. **Configuraci√≥n del entorno**  
   - Se solicita al usuario la clave de OpenAI (`OPENAI_API_KEY`) con `getpass` o se carga autom√°ticamente desde las variables de entorno.
2. **Inicializaci√≥n del modelo y embeddings**  
   - Se crea un objeto `ChatOpenAI` para el modelo `gpt-4o-mini`.  
   - Se prueban los embeddings con `OpenAIEmbeddings`.
3. **Definici√≥n de un PromptTemplate**  
   - Se usa `ChatPromptTemplate` para definir la estructura del mensaje (system y human).
4. **Creaci√≥n del Chain**  
   - Se combina el prompt con el modelo (`prompt | llm`).
5. **Invocaci√≥n**  
   - El usuario ingresa una pregunta y el modelo genera una respuesta.

---

## üìÇ Estructura del repositorio
```
basic-langchain/
‚îú‚îÄ‚îÄ lang-chain.ipynb       # Notebook principal con la implementaci√≥n
‚îú‚îÄ‚îÄ .gitignore             # Archivos ignorados (entornos, claves, etc.)
‚îî‚îÄ‚îÄ README.md              # Este archivo
```

---

## ‚öôÔ∏è Requisitos

### Python
Se recomienda usar **Python 3.11** o superior (evitar 3.14 por problemas de compatibilidad con numpy).

### Dependencias
Inst√°lalas con:
```bash
pip install langchain langchain-openai python-dotenv tiktoken
```

### Variables de entorno
Crea un archivo `.env` en la ra√≠z del proyecto:
```
OPENAI_API_KEY=sk-xxxxxx
```

O bien, puedes ingresar tu clave al ejecutar el notebook cuando te la pida:
```python
import getpass, os
os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter your OpenAI API key: ")
```

---

## ‚ñ∂Ô∏è Ejecuci√≥n

Abre el notebook:
```bash
jupyter notebook lang-chain.ipynb
```

Y ejecuta las celdas paso a paso.  
Al final podr√°s invocar el modelo con un texto, por ejemplo:

```python
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2)
prompt = ChatPromptTemplate.from_messages([
    ("system", "Eres un asistente amable y preciso."),
    ("human", "Explica qu√© es un modelo de lenguaje en 3 l√≠neas.")
])
chain = prompt | llm
response = chain.invoke({"input": ""})
print(response.content)
```

**Salida esperada:**
```
Un modelo de lenguaje predice texto a partir de contexto previo.
Aprende patrones y relaciones entre palabras mediante entrenamiento masivo.
Se usa para tareas como generaci√≥n, traducci√≥n o chatbots.
```

---

## üìö Referencias
- [LangChain LLM Chain Tutorial](https://python.langchain.com/docs/tutorials/llm_chain/)
- [OpenAI API Docs](https://platform.openai.com/docs/)
- [LangChain Chat Models](https://python.langchain.com/docs/integrations/chat/openai/)
